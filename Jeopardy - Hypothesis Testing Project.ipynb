{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We'll begin by importing the csv file and printing the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jeopardy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                                                                                      Question  \\\n",
      "0             For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory   \n",
      "1  No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves   \n",
      "2                     The city of Yuma in this state has a record average of 4,055 hours of sunshine each year   \n",
      "3                         In 1963, live on \"The Art Linkletter Show\", this company served its billionth burger   \n",
      "4     Signer of the Dec. of Indep., framer of the Constitution of Mass., second President of the United States   \n",
      "\n",
      "       Answer  \n",
      "0  Copernicus  \n",
      "1  Jim Thorpe  \n",
      "2     Arizona  \n",
      "3  McDonald's  \n",
      "4  John Adams  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Printing the columns it becomes evident some have unecessary\n",
    "        white spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.replace(' ', \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show_Number', 'Air_Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        This removed the white spaces from our column titles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Our Data based on Question Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        We'll begin by creating a function that'll enable us to filter questions \n",
    "        containing a pre-defined list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(dataset, filter_words):\n",
    "    filter_function = lambda x: all(word.lower() in x.lower() for word in filter_words)\n",
    "    # Converted everything to lowercase to avoid any issues due to capitalization\n",
    "    return dataset.loc[dataset['Question'].apply(filter_function)]\n",
    "    # This returns the rows where the question contained all of the specified words from our list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        all(list comprehension) goes through the various words in filter_words and \n",
    "        evaluates them to see if they're in the question.\n",
    "        \n",
    "        It'll return true if all of our words are within the question; else it returns\n",
    "        false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_applied = filter_data(df,['King', 'England'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Any returns rows must contain 'King' and 'England' within their questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_applied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        This is used as a final check to examine how many rows met our condition list above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Numbers to Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216930 entries, 0 to 216929\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Show_Number  216930 non-null  int64 \n",
      " 1   Air_Date     216930 non-null  object\n",
      " 2   Round        216930 non-null  object\n",
      " 3   Category     216930 non-null  object\n",
      " 4   Value        216930 non-null  object\n",
      " 5   Question     216930 non-null  object\n",
      " 6   Answer       216928 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        This gives us a better sense of our columns and their data types. If we want to \n",
    "        have greater functionality of the Value column we'd need to change it to the float\n",
    "        datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Value = df.Value.str.lstrip(\"$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Values to Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion = lambda x: float(x.replace(',','') if x != 'None' else 0)\n",
    "df['Value'] = df['Value'].apply(conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        After completing this step our value for the 'Value' column will be float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Value of Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Let's say we're very knowledgeable about 'Kings'. We can calculate the mean of \n",
    "        questions related to our topic of expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771.8833850722094"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_expertise = filter_data(df,['King'])\n",
    "topic_expertise.Value.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Here we can see the average value of questions related to 'Kings' is $771.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining Different Answers to Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Since we're an expert on the topic of 'king' let's explore what different\n",
    "        answers there are to questions related to our expertise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers(filtered_dataset):\n",
    "    return filtered_dataset['Answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Henry VIII           55\n",
       "Solomon              35\n",
       "Richard III          33\n",
       "Louis XIV            31\n",
       "David                30\n",
       "                     ..\n",
       "an oratory            1\n",
       "void                  1\n",
       "the Blarney Stone     1\n",
       "Constantine (II)      1\n",
       "the crown             1\n",
       "Name: Answer, Length: 5268, dtype: int64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers(topic_expertise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Date to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Air_Date'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        This converts the values into datatime datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity of Computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        We'll analyze the popularity of computer using the number of questions that \n",
    "        explicit contain 'computer' as a proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_filter = filter_data(df,['Computer'])\n",
    "# Creating a new dataframe with questions containing 'computer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        We'll divide this analysis into two times periods.\n",
    "            Period One: January 1, 1990 - December 31, 1999\n",
    "            Period Two: January 1, 2000 - December 31, 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_filter_90s = computer_filter[(computer_filter['Date'] > datetime.datetime(1990,1,1)) & (computer_filter['Date'] < datetime.datetime(1999,12,31))]\n",
    "                      # Used datetime.datetime to get datetime64[ns]; this enables us to compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_filter_20s = computer_filter[(computer_filter['Date'] > datetime.datetime(2000,1,1)) & (computer_filter['Date'] < datetime.datetime(2009,12,31))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the period from 1990 - 1999 there were 98 questions regarding computers.\n",
      "Whereas the period from 2000 - 2009 featured 267 questions regarding computers\n"
     ]
    }
   ],
   "source": [
    "print('In the period from 1990 - 1999 there were {} questions regarding computers.\\nWhereas the period from 2000 - 2009 featured {} questions regarding computers'.format(str(len(computer_filter_90s)),str(len(computer_filter_20s))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Futher Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Let's say we wanted to investigate this further and check the popularity of \n",
    "        'computers' on a yearly basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = pd.to_numeric(df['Air_Date'].str[:4])\n",
    "# Creates a new column with numerical year values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_filter_yearly = filter_data(df,['Computer'])\n",
    "# Creates a new dataset to examine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Let's group the frequency of computer related questions by the year they appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_year_sort = computer_filter_yearly.groupby(['Year']).Show_Number.count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        This returns the year with the number of questions explicitly mentioning\n",
    "        'computer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computer_year_sort.max()[0]\n",
    "# This returns the year with the greatest number of questions that explicit contains 'computer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computer_year_sort.max()[1]\n",
    "# This returns the number of question within the most popular year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Let's build a short program that enables users to randomly test their \n",
    "        knowledge using our jeopardy questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_generator(dataframe):\n",
    "    selection = 'yes'\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    while selection == 'yes':\n",
    "        \n",
    "        # This generates a random question for the user\n",
    "        random_question = random.randint(1, len(dataframe))\n",
    "        print(dataframe.Question[random_question])\n",
    "        \n",
    "        # This provides users the ability to answer the question\n",
    "        user_input = input()\n",
    "        \n",
    "        # This checks if the answer is correct\n",
    "        if user_input.lower() == dataframe.Answer[random_question].lower():\n",
    "            correct += 1\n",
    "            if correct > 1 and wrong > 1:\n",
    "                print('Correct! You have {0} correct answers and {1} wrong answers'.format(str(correct), str(wrong)))\n",
    "            elif correct > 1 and wrong == 1:\n",
    "                print('Correct! You have {0} correct answers and {1} wrong answer'.format(str(correct), str(wrong)))\n",
    "            elif correct > 1 and wrong == 0:\n",
    "                print('Correct! You have {0} correct answers and no wrong answer'.format(str(correct)))\n",
    "            elif correct == 1 and wrong == 0:\n",
    "                print('Correct! You have {0} correct answer and no wrong answer'.format(str(correct)))\n",
    "            elif correct == 1 and wrong > 1:\n",
    "                print('Correct! You have {0} correct answer and {1} wrong answer'.format(str(correct), str(wrong)))\n",
    "        else:\n",
    "            wrong += 1\n",
    "            if correct > 1 and wrong > 1:\n",
    "                print('Wrong! You have {0} correct answers and {1} wrong answers.'.format(str(correct), str(wrong)))\n",
    "            elif correct > 1 and wrong == 1:\n",
    "                print('Wrong! You have {0} correct answers and {1} wrong answer'.format(str(correct), str(wrong)))\n",
    "            elif correct == 0 and wrong == 1:\n",
    "                print('Wrong! You have no correct answers and {0} wrong answer'.format(str(wrong)))\n",
    "            elif correct == 1 and wrong == 1:\n",
    "                print('Wrong! You have {0} correct answer and {1} wrong answer.'.format(str(correct), str(wrong)))\n",
    "            elif correct == 0 and wrong > 1:\n",
    "                print('Wrong! You have no correct and {0} wrong answer.'.format(str(wrong)))\n",
    "            print('Please try again! The correct answer was ' + str(dataframe.Answer[random_question].lower()))\n",
    "\n",
    "        print()\n",
    "        print('If you\\'d like another question please type \\'yes\\'. If not please type \\'no\\'')\n",
    "\n",
    "        response = input()\n",
    "    \n",
    "        # This would keep running the game if user selects 'yes'\n",
    "        if response.lower() == 'yes':\n",
    "              selection = 'yes'\n",
    "        elif response.lower() == 'no':\n",
    "              selection = 'no'\n",
    "              print(\"Goodbye\")\n",
    "        else:\n",
    "              print('Invalid response! Program will close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_generator(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
